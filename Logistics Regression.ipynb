{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# always scale down the variables when the model is distance based\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Social_Network_Ads.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17112\\2691078144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Social_Network_Ads.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Age and estimatedsalary , they have different ranges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#We convert the values of age and estimatedsalary within the range of 0 to 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Social_Network_Ads.csv'"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('Social_Network_Ads.csv')\n",
    "dataset\n",
    "\n",
    "#Age and estimatedsalary , they have different ranges\n",
    "#We convert the values of age and estimatedsalary within the range of 0 to 1\n",
    "# once these values are converted in same range, it is easy to plot them\n",
    "# this is necessary for the models which are based on distance of values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting  Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:,[2,3]].values    #Features / predictors\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = dataset.iloc[:,4].values   #Target variable\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=1/3,random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the independent variables\n",
    "\n",
    "standard_Scaler=StandardScaler()\n",
    "X_train = standard_Scaler.fit_transform(X_train)   #fit generates the parameters, transform applies \n",
    "x_test = standard_Scaler.transform(x_test)\n",
    "\n",
    "#fitted only on the train dataset\n",
    "#transformed both train and test based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiating and fitting the model to training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg=LogisticRegression()   #Instantiation\n",
    "log_reg.fit(X_train,y_train)    #training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=log_reg.predict(x_test)\n",
    "y_pred   #Predicted y test values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test  #actual y test values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74,  7],\n",
       "       [13, 40]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test, y_pred)\n",
    "conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f9fca2dbb50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the confusion matrix shows the same format everytime: (TN , FP, FN , TP) with actuals being the rows and predicted being the columns\n",
    "\n",
    "conf_matrix = plot_confusion_matrix(log_reg,x_test,y_test)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8507462686567164\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred))   #  (TP + TN )/ Total  = (74+40)/134 = 114/134\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.851063829787234\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", precision_score(y_test,y_pred))    #(TP / Total predicted positive) = 40/ (40+7) = 0.85\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.7547169811320755\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: \", recall_score(y_test,y_pred))      #(TP / Total actual positves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88        81\n",
      "           1       0.85      0.75      0.80        53\n",
      "\n",
      "    accuracy                           0.85       134\n",
      "   macro avg       0.85      0.83      0.84       134\n",
      "weighted avg       0.85      0.85      0.85       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=log_reg.predict(x_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01016366 0.98983634]\n",
      " [0.97013083 0.02986917]\n",
      " [0.93360052 0.06639948]\n",
      " [0.06840191 0.93159809]\n",
      " [0.04854055 0.95145945]\n",
      " [0.6769741  0.3230259 ]\n",
      " [0.95829933 0.04170067]\n",
      " [0.13195169 0.86804831]\n",
      " [0.11859357 0.88140643]\n",
      " [0.96067008 0.03932992]\n",
      " [0.65779746 0.34220254]\n",
      " [0.99146972 0.00853028]\n",
      " [0.08630966 0.91369034]\n",
      " [0.99382655 0.00617345]\n",
      " [0.99217162 0.00782838]\n",
      " [0.71100361 0.28899639]\n",
      " [0.97604078 0.02395922]\n",
      " [0.34882082 0.65117918]\n",
      " [0.99374865 0.00625135]\n",
      " [0.02232072 0.97767928]\n",
      " [0.35409727 0.64590273]\n",
      " [0.97720436 0.02279564]\n",
      " [0.03492051 0.96507949]\n",
      " [0.11413448 0.88586552]\n",
      " [0.57995133 0.42004867]\n",
      " [0.46302971 0.53697029]\n",
      " [0.9488691  0.0511309 ]\n",
      " [0.93281404 0.06718596]\n",
      " [0.14437257 0.85562743]\n",
      " [0.5075021  0.4924979 ]\n",
      " [0.06384701 0.93615299]\n",
      " [0.27178909 0.72821091]\n",
      " [0.99063519 0.00936481]\n",
      " [0.07359742 0.92640258]\n",
      " [0.69936466 0.30063534]\n",
      " [0.61119807 0.38880193]\n",
      " [0.98860368 0.01139632]\n",
      " [0.04646878 0.95353122]\n",
      " [0.92803925 0.07196075]\n",
      " [0.96503506 0.03496494]\n",
      " [0.53161078 0.46838922]\n",
      " [0.9407846  0.0592154 ]\n",
      " [0.23527397 0.76472603]\n",
      " [0.99159879 0.00840121]\n",
      " [0.94328483 0.05671517]\n",
      " [0.04693013 0.95306987]\n",
      " [0.02010197 0.97989803]\n",
      " [0.97987206 0.02012794]\n",
      " [0.43533185 0.56466815]\n",
      " [0.9712178  0.0287822 ]\n",
      " [0.91440102 0.08559898]\n",
      " [0.46367393 0.53632607]\n",
      " [0.9758623  0.0241377 ]\n",
      " [0.88340294 0.11659706]\n",
      " [0.86465453 0.13534547]\n",
      " [0.99568021 0.00431979]\n",
      " [0.05596536 0.94403464]\n",
      " [0.99703928 0.00296072]\n",
      " [0.09599328 0.90400672]\n",
      " [0.7744492  0.2255508 ]\n",
      " [0.99640993 0.00359007]\n",
      " [0.67530896 0.32469104]\n",
      " [0.9922703  0.0077297 ]\n",
      " [0.13638776 0.86361224]\n",
      " [0.13759306 0.86240694]\n",
      " [0.91598357 0.08401643]\n",
      " [0.50620694 0.49379306]\n",
      " [0.10834414 0.89165586]\n",
      " [0.9905174  0.0094826 ]\n",
      " [0.26382601 0.73617399]\n",
      " [0.81691496 0.18308504]\n",
      " [0.96460106 0.03539894]\n",
      " [0.13430477 0.86569523]\n",
      " [0.07256719 0.92743281]\n",
      " [0.32553889 0.67446111]\n",
      " [0.2902899  0.7097101 ]\n",
      " [0.95839603 0.04160397]\n",
      " [0.74619591 0.25380409]\n",
      " [0.94476404 0.05523596]\n",
      " [0.64855962 0.35144038]\n",
      " [0.67306953 0.32693047]\n",
      " [0.25407718 0.74592282]\n",
      " [0.01101601 0.98898399]\n",
      " [0.97199012 0.02800988]\n",
      " [0.19100339 0.80899661]\n",
      " [0.03035049 0.96964951]\n",
      " [0.8447674  0.1552326 ]\n",
      " [0.10025973 0.89974027]\n",
      " [0.06445909 0.93554091]\n",
      " [0.5923163  0.4076837 ]\n",
      " [0.46113957 0.53886043]\n",
      " [0.95524884 0.04475116]\n",
      " [0.98810454 0.01189546]\n",
      " [0.9972564  0.0027436 ]\n",
      " [0.8123217  0.1876783 ]\n",
      " [0.92954795 0.07045205]\n",
      " [0.76129969 0.23870031]\n",
      " [0.99392018 0.00607982]\n",
      " [0.83798745 0.16201255]\n",
      " [0.97307926 0.02692074]\n",
      " [0.52019352 0.47980648]\n",
      " [0.61905219 0.38094781]\n",
      " [0.96968696 0.03031304]\n",
      " [0.70417426 0.29582574]\n",
      " [0.72185094 0.27814906]\n",
      " [0.98935128 0.01064872]\n",
      " [0.02565311 0.97434689]\n",
      " [0.08936928 0.91063072]\n",
      " [0.82916712 0.17083288]\n",
      " [0.83167364 0.16832636]\n",
      " [0.78105009 0.21894991]\n",
      " [0.37884606 0.62115394]\n",
      " [0.34478873 0.65521127]\n",
      " [0.8327355  0.1672645 ]\n",
      " [0.97668678 0.02331322]\n",
      " [0.7294534  0.2705466 ]\n",
      " [0.71150116 0.28849884]\n",
      " [0.60150473 0.39849527]\n",
      " [0.99419074 0.00580926]\n",
      " [0.55373596 0.44626404]\n",
      " [0.71309396 0.28690604]\n",
      " [0.46930963 0.53069037]\n",
      " [0.90389233 0.09610767]\n",
      " [0.95279345 0.04720655]\n",
      " [0.9930299  0.0069701 ]\n",
      " [0.72185094 0.27814906]\n",
      " [0.72842959 0.27157041]\n",
      " [0.03382502 0.96617498]\n",
      " [0.47693372 0.52306628]\n",
      " [0.30630966 0.69369034]\n",
      " [0.98447843 0.01552157]\n",
      " [0.92056062 0.07943938]\n",
      " [0.9758623  0.0241377 ]\n",
      " [0.72237083 0.27762917]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = log_reg.predict_proba(x_test)\n",
    "print(y_pred_proba)\n",
    "\n",
    "# print(y_pred_proba[::,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98983634, 0.02986917, 0.06639948, 0.93159809, 0.95145945,\n",
       "       0.3230259 , 0.04170067, 0.86804831, 0.88140643, 0.03932992,\n",
       "       0.34220254, 0.00853028, 0.91369034, 0.00617345, 0.00782838,\n",
       "       0.28899639, 0.02395922, 0.65117918, 0.00625135, 0.97767928,\n",
       "       0.64590273, 0.02279564, 0.96507949, 0.88586552, 0.42004867,\n",
       "       0.53697029, 0.0511309 , 0.06718596, 0.85562743, 0.4924979 ,\n",
       "       0.93615299, 0.72821091, 0.00936481, 0.92640258, 0.30063534,\n",
       "       0.38880193, 0.01139632, 0.95353122, 0.07196075, 0.03496494,\n",
       "       0.46838922, 0.0592154 , 0.76472603, 0.00840121, 0.05671517,\n",
       "       0.95306987, 0.97989803, 0.02012794, 0.56466815, 0.0287822 ,\n",
       "       0.08559898, 0.53632607, 0.0241377 , 0.11659706, 0.13534547,\n",
       "       0.00431979, 0.94403464, 0.00296072, 0.90400672, 0.2255508 ,\n",
       "       0.00359007, 0.32469104, 0.0077297 , 0.86361224, 0.86240694,\n",
       "       0.08401643, 0.49379306, 0.89165586, 0.0094826 , 0.73617399,\n",
       "       0.18308504, 0.03539894, 0.86569523, 0.92743281, 0.67446111,\n",
       "       0.7097101 , 0.04160397, 0.25380409, 0.05523596, 0.35144038,\n",
       "       0.32693047, 0.74592282, 0.98898399, 0.02800988, 0.80899661,\n",
       "       0.96964951, 0.1552326 , 0.89974027, 0.93554091, 0.4076837 ,\n",
       "       0.53886043, 0.04475116, 0.01189546, 0.0027436 , 0.1876783 ,\n",
       "       0.07045205, 0.23870031, 0.00607982, 0.16201255, 0.02692074,\n",
       "       0.47980648, 0.38094781, 0.03031304, 0.29582574, 0.27814906,\n",
       "       0.01064872, 0.97434689, 0.91063072, 0.17083288, 0.16832636,\n",
       "       0.21894991, 0.62115394, 0.65521127, 0.1672645 , 0.02331322,\n",
       "       0.2705466 , 0.28849884, 0.39849527, 0.00580926, 0.44626404,\n",
       "       0.28690604, 0.53069037, 0.09610767, 0.04720655, 0.0069701 ,\n",
       "       0.27814906, 0.27157041, 0.96617498, 0.52306628, 0.69369034,\n",
       "       0.01552157, 0.07943938, 0.0241377 , 0.27762917])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = y_pred_proba[::,1]\n",
    "y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.roc_curve returns three outputs: fpr, tpr and different thresholds\n",
    "from sklearn import metrics\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,  y_pred_proba)   #y_pred (.75, .95)\n",
    "\n",
    "#metrics.roc_auc_score directly returns the auc for y_actual and corresponding prob values of success for each row\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Plotting the AUC curve\n",
    "plt.figure(figsize=(10,8))\n",
    "# plt.plot(fpr,tpr,label=\"ROC\")\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "# plt.legend(loc=4)\n",
    "plt.title(\"Receiver Operating Characteristic Curve (ROC)\")\n",
    "plt.xlabel(\"FPR ---->\")\n",
    "plt.ylabel(\"TPR ---->\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9280223619846262"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)     #returns the single auc value\n",
    "auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.989836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.936153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.855627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.808997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.745923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.736174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.709710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.674461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.621154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.564668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.538860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.536970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.523066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.493793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.479806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.468389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.446264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.420049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.398495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.388802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.380948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.300635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.295826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.288996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.288499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.286906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.278149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.277629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.271570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.225551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.187678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.183085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.162013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.155233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.067186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.066399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.026921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.024138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TPR       FPR  Threshold\n",
       "0   0.000000  0.000000   1.989836\n",
       "1   0.018868  0.000000   0.989836\n",
       "2   0.226415  0.000000   0.944035\n",
       "3   0.226415  0.012346   0.936153\n",
       "4   0.528302  0.012346   0.855627\n",
       "5   0.528302  0.024691   0.808997\n",
       "6   0.566038  0.024691   0.745923\n",
       "7   0.566038  0.037037   0.736174\n",
       "8   0.603774  0.037037   0.709710\n",
       "9   0.603774  0.061728   0.674461\n",
       "10  0.679245  0.061728   0.621154\n",
       "11  0.679245  0.074074   0.564668\n",
       "12  0.698113  0.074074   0.538860\n",
       "13  0.698113  0.086420   0.536970\n",
       "14  0.754717  0.086420   0.523066\n",
       "15  0.754717  0.098765   0.493793\n",
       "16  0.792453  0.098765   0.479806\n",
       "17  0.792453  0.111111   0.468389\n",
       "18  0.811321  0.111111   0.446264\n",
       "19  0.811321  0.123457   0.420049\n",
       "20  0.849057  0.123457   0.398495\n",
       "21  0.849057  0.135802   0.388802\n",
       "22  0.867925  0.135802   0.380948\n",
       "23  0.867925  0.209877   0.300635\n",
       "24  0.886792  0.209877   0.295826\n",
       "25  0.886792  0.222222   0.288996\n",
       "26  0.905660  0.222222   0.288499\n",
       "27  0.905660  0.234568   0.286906\n",
       "28  0.905660  0.259259   0.278149\n",
       "29  0.905660  0.271605   0.277629\n",
       "30  0.924528  0.271605   0.271570\n",
       "31  0.924528  0.308642   0.238700\n",
       "32  0.943396  0.308642   0.225551\n",
       "33  0.943396  0.333333   0.187678\n",
       "34  0.962264  0.333333   0.183085\n",
       "35  0.962264  0.382716   0.162013\n",
       "36  0.981132  0.382716   0.155233\n",
       "37  0.981132  0.493827   0.067186\n",
       "38  1.000000  0.493827   0.066399\n",
       "39  1.000000  0.691358   0.026921\n",
       "40  1.000000  0.716049   0.024138\n",
       "41  1.000000  1.000000   0.002744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['TPR'] = tpr\n",
    "df['FPR'] = fpr\n",
    "df['Threshold']= threshold\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"detailed_analysis_fpr_tpr.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
